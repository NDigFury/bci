---
title: "BCI"
subtitle: "APCV 399: Reserach Assistant"
author: "Nikki Diguardi"
date: "`r format(Sys.time(), '%A, %B %d, %Y')`"
always_allow_html: yes
output:
  bookdown::html_document2:
    toc: yes
    toc_depth: 2
    number_sections: false
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 2
    
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
library(rmarkdown)
library(knitr)
#library(ggplot2)
#library(tinytex)
#library(anicon)

# Try knitting this file!

# If you try to knit to PDF and run into a strange error,
# then run tinytex::install_tinytex()

knitr::opts_chunk$set(echo = FALSE)
```

<!--

2023-03-22 thoughts

+ Great start.
+ Since you can't really "test" much of this, here's how I think you should proceed:
	+ Through your research on the topic, you could begin constructing a systematic comparison of the different products/approaches listed here
	+ Look at consistent messaging these companies put out. What problem do they all want to solve? What features do they have in common they're promising?
	+ Where do they differ? 
	+ Look at any other data points you can glean from the information that's available.
	+ Align this with the research articles that are out there and try to come up with a matrix that's informed by the empirical research _and_ the promises/realities of these companies/devices.
	+ You'll want to exhaust the available research until you feel you've reached a "saturation" point, where more literature likely won't move the needle much.
	+ Then, start scoring them. 
+ You're not going for a review article, necessarily, but a systematic approach to understanding the landscape that's evidence-based and supported by the research available.
+ Then, once you've got that, your "What will the future look like?" section of your paper will be much more robust and guided.
+ To get this matrix sorted out, it's going to take some deep reading and unpacking of the products/companies' websites, news releases, et cetera, so be very meticulous about it.
  + You'll want to make note of your approach (how you find the information), what was available and what _wasn't_, which companies are more forthcoming and possibly why that might be, where funding for the companies came from (ie, NIH grants, venture capitalists, etc) and so on.
    + Creating a spreadsheet is probably the best approach.

-->


## Intial thoughts

I find thinking about living in a world that has the ability to have universal language or the ability to speak with any being that has a brain to be really inspirational. Currently we can read what our thoughts are thinking and the different interaction with BCI can frame the future in what we should be expecting. I am expecting to not re-write thoughts but, to communicate back to the brain using the same features and methods to read outputs from the brain. We can better understand interpretation of the brain's rendering emotions, visual, or medication. Could we preform surgery on the body without the brain knowing? Could the blind see? Can Alzheimer's be a thing of the past?

This is what I am hoping to find out about. Where is our current state of BCI, where is BCI going, and why haven't my dreams been rendered? 3D- printed food, talking to someone on video chat from across the world, animal products are for more than just food, a pig's valve in a humans heart, or a real functioning light saber. These were dreams that have been processed and created in the modern world with our technology. Yet, we seem to be lacking in other spaces or science has slowed down of an unknown cause.

This paper or presentation is to address the approaches to Brain-Computer-Interaction (BCI). Why we have these poteintally archaic functions, how can the feild progress, and what the current compaines are doing about the technological shift. Since I have access to an EEG we are going to try and find the limitations to the technology and how can we advance to the next BCI phase. It seems like every scientist and programmer that 'falls down this rabbit hole' draws the same conculsion: BCI can aid so many people the goals of some of the companies featured below were: To give blind the ability to see, store memories outside the brain, give those that require robotic limbs the freedom to move on their own, and to lessen the effects of mental illness.

<!-- Thought could the lab create a mimic study like: we have the EEG, now food for thought 
Evaluating a Semiautonomous Brain-Computer Interface
Based on Conformal Geometric Algebra and Artificial Vision
Mauricio Adolfo Ramı´rez-Moreno and David Gutie´rrez
Centro de Investigacio´n y de Estudios Avanzados (Cinvestav), Unidad Monterrey, Apodaca, Nuevo Leon 66600, Mexico
Correspondence should be addressed to David Gutie´rrez; dgtz@ieee.org
Received 10 June 2019; Accepted 30 October 2019; Published 27 November 2019
Guest Editor: Hyun S. Kim -->

## Past, Present, Future Article

"The electroencephalography (EEG)-based brain–computer interface (BCI) is one of the most rapidly developing fields of BCI and has potential to expand far beyond the domain of medical applications, in which they were initially most popular." [@varbu2022past] Personally using the Enchanted Wave to see how EEG see's my brain patterning is the first move. 


### Overview of Challenges and opportunities for future of brain-coputer interface in neurorehabilitation

BRIEF THOUGHTS::
The main idea of this article is to explore the advancements in overcoming paralysis or debilitating motor function. They are looking at BCI, the current advancement in enhancing the CNS (central nervous system) communication to allow patients after a nervous system issue, forerunner is s constraint-induced movement therapy (CIMT). The article goes into different functions that BCI can aid during therapy. Yet, since there is a existing treatment in CIMT the current mindset is 'if it ain't broke don't fix it.' I feel like the advancements in medical history would be more important for patient care. There is also the uphill battle of having to train the brain in interacting with the limbs. Which can be frustrating and some people end after the first day.But there is hope on creating a more tailored experience with Machine Learning techniques and choose to reduce the difficultly of user interaction.

GOOD QUOTES::

it would facilitate rehabilitation to commence earlier following brain damage and provides options for patients who are unable to partake in traditional physical therapy.

We propose that addressing the speed and effectiveness of learning BCI control are priorities for the field, which may be improved by multimodal or multi-stage approaches harnessing more sensitive neuroimaging technologies in the early learning stages, before transitioning to more practical, mobile implementations.

Non-invasive brain-computer (and brain-machine) interfaces provide an advanced technological solution, decoding brain
signals directly from the scalp and translating them into movement of a virtual (on screen) or robotic effector.

Non-invasive BCI typically consists of three key components: A recorder, a decoder, and an effector. The recorder acquires brain signals from the scalp surface.

Four different types: In most cases the recorder is an electroencephalogram (EEG) detecting scalp electrical fluctuations associated with neuronal activity. In practise, any neural signal could be incorporated into a BCI, and implementations using magnetoencephalography (MEG) (Buch et al., 2008; Foldes et al., 2015), functional magnetic
resonance imaging (fMRI) (Thibault et al., 2018) and functional near-infrared spectroscopy (fNIRS) (Soekadar et al., 2021) have also shown merit.

Current implementations of EEG-BCI are not well adapted for this purpose as they are cumbersome, require lengthy
setup times with wet electrolyte-filled sensors, and a skilled operator to ensure sufficient signal quality, positioning of the headgear and execution of (often custom written and not user friendly) software.

Addressing BCI inefficiency and speed of learning are priorities for the field, which may be improved by multimodal or multi-stage BCI approaches harnessing more sensitive neuroimaging technologies in the early learning stages, before transitioning to more practical, mobile implementations.

### Study of the Auxiliary Robot Used to Disassemb and Assemb Mid-Set Switch Cubicle Based on BCI
> change the bibtex :: Study of the Auxiliary Robot Used
to Disassemb and Assemb Mid-Set Switch
Cubicle Based on BCI
Weiwei Huang(&)
, Bihui Zhang, and Rui Li
Zhaotong Power Supply Bureau of Yunnan Power Grid Co., Ltd.,
Zhaotong 657000, Yunnan, China >

Brief Thoughts ::

Switchgear is a power equipment, to maintain the power supply there is a transformer that takes assembly and disassembly. To reduce injury the article suggests using an EEG device. IT goes through the experiment where 12 sujects try the device using their eyes to remove the transformer and replace the transformer. They used brain mapping to ensure the device was calibrated properly. Not right for the article.

GOOD QUOTES ::

It can be concluded that the working efficiency of the brain-computer aided mode is improved by nearly 60%
compared with the traditional mode

Inside ergonomics article ::
add to bibtex

Advances in Hybrid Brain-Computer Interfaces: Principles,
Design, and Applications
Zina Li, Shuqing Zhang, and Jiahui Pan
South China Normal University, Guangzhou 510631, China
Correspondence should be addressed to Jiahui Pan; panjh82@qq.com
Received 20 June 2019; Revised 9 September 2019; Accepted 17 September 2019; Published 8 October 2019
Guest Editor: Hyun J. Baek

### Brief overview

A tight view of EEG, why is it used, why is it so popular and how can we make it better? Currently EEG has the most adaptive paridigms for creating algorithms for hBCI collection and intreptation. By just reading the surface of the brain interaction there may have effects like mental fatigue, information transfers at a lower rate (see my 'sleeping' EEG), issues with multi-controls, and false readings. They tested the hBCI which developes the EEG but also queues audio and visual (thought like the VR controller from Neuable as it took eye movement as a factor). They did a study on 80 trials with healthy participants it took about an hour and a half for the participants to get used to the controls.

### GOOD QUOTES

Conventional brain-computer interface (BCI) systems have been facing two fundamental challenges: the lack of high detection performance and the control command problem

The most commonlyused methods of extracting brain signals are nonimplanting, including functional magnetic resonance imaging (fMRI), magnetoencephalography (MEG), electroencephalography (EEG), and functional near-infrared spectroscopy (fNIRS) [2]. Although EEG has low signal-to-noise ratio and spatial resolution, it has been widely used in BCI because of its noninvasiveness, portability, low cost, good performance, real-time response, and technical requirements lower than other brain signals

Pfurtscheller et al. [10] believed that in addition to the simple combination of different BCIs, the type of hBCI should meet the following four criteria: (1) the activity comes directly from the brain; (2) at least one brain signal acquisition method should be used to capture this activity, and the brain signal acquisition method can be in the form of electrical, magnetic, or hemodynamic changes; (3) the signal must be processed in real time/online to establish communication between the brain and the computer to generate control commands; (4) feedback must be provided according to the results of brain activity for communication and control.

The BCI system used the characteristics of P300 and SSVEP to detect which photo the patient had noticed. Eight patients (four in the vegetative state (VS), three in the minimally conscious state (MCS), and one in the locked-in syndrome (LIS)) participated in the experiment. Using the SVM-based classifier, one VS patient, one MCS patient, and one LIS patient were able to select photos of themselves or others (classification accuracy, 66%–100%), which indicates that the patient command can be
followed using an hybrid BCI and further proves that they have certain cognitive abilities and awareness.

Humans have multiple senses that provide pathways for processing information on the reality. The integration of multiple sensory stimuli enhances top-down attention,
and these enhanced effects may be conducive to improve the performance of BCI systems. (They make a good point and this is important)

##Current Companies and their Development

There are currently 4 companies that I think should be highlighted with pushing the brain computer interaction into the next phase. If there was some way of altering or combining what they have created to understanding true interaction with the brain.

<!-- Create a table here of the compaines and thier goals vs what they have created ,, a overview of their approaches and their tech. -->

## Current Companies and their Development

There are currently 4 companies that I think should be highlighted with pushing the brain computer interaction into the next phase. If there was some way of altering or combining what they have created to understanding true interaction with the brain.
 

### Neuralink

Founded by Elon Musk with the goal of creating symbiotic relationship between brain and computer. Currently their product is not available to the public. They have created threads that are woven into the brain to allow communication to different devices. They are hoping to develop their tech to not include an invasive surgery yet, currently they can control Bluetooth and 'mouse' like features on the computer.


### Neurable

They were most know for creating a the world's first brain controlled VR game where the user would drive a car with an EEG headset. Currently, they have created headphones which monitor using brainwaves to ensure focus. The features for the head phones are vast as they are the first iteration of 'smart-headphones' with touchless controls. They are working with the military on training ideas. But, there is not much ideas for the public on the VR domain side.


### BrainPort

This company is less known here int he states since 2009 as their devices are more used in Europe. They have wearable devices for the blind to interpret sight via their tongue. There is an electric 'lollipop' that send the signal to the brain to comprehend as a view-able object through training sessions. I feel like the understanding that this company is doing is important to better understand what our interaction and communication with the brain could be like.


### Kernel

The goal is to store memories outside of the brain and upload new memories. They use their device called the Kernel Flow a near-infrared spectroscopy (TD-fNIRS) which is a imagining for high resolution observations. They have partnered with AppliedVR to measure treatment of chronic pain.


## References
